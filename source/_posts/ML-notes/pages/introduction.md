---
title: ML-notes:绪论
date: 2024-04-14 13:10:52
tags: [ML-notes,ML,notes]
---

# 1 绪论

##  1. <a name='1'>概念</a>

机器学习是从人工智能中产生的一个重要学科分支，是实现智能化的关键。


**机器学习**是一类算法的总称，这些算法企图从大量历史数据中挖掘出其中隐含的规律，并用于预测或者分类，更具体的说，机器学习可以看作是寻找一个函数，输入是样本数据，输出是期望的结果，只是这个函数过于复杂，以至于不太方便形式化表达。也就是**经典定义**：<u>利用经验改善系统自身的性能。（从 经验到数据 的过程）</u>

在计算机系统中，**经验**通常以**数据**形式存在，因此，机器学习研究的主要内容，是关于在计算机上**从数据中产生模型**的算法，即**学习算法**。

> “Learning is any process by which a system improves performance from experience.” 
> -- Herbert Simon

> Machine learning aims to study Approaches which improve the Performance of a machine at a specific Task with Experiences.

> 也就是说 **机器学习 = 任务 + 方法 + 经验 + 性能**

##  2. <a name='2'>三个概念之间的关系</a>

当学到机器学习最容易问的就是 三个概念 之间的关系了：机器学习、深度学习、人工智能。其实关系如下图一样：
<div align=center>
<img src="/img/pics/1-1.png" />
</div>

- **机器学习**是人工智能的一个子领域，是**人工智能的核心**
- **深度学习**是机器学习的一个子领域，是目前最火的**方向**
- **机器学习是从数据通往智能的技术途径，是现代人工智能的本质**

由机器学习也延展出很多技术：

<div align=center>
<img src="/img/pics/1-2.png" />
</div>

##  3. <a name='3'>TAEP</a>
###  3.1. <a name='3-1'>概念</a>
通常描述机器学习的应用用 TAEP 来描述：
- 任务-Task：机器学习要解决的问题（研究对象）
- 方法-Approach：各种机器学习方法（核心内容）
- 经验-Experience：训练模型的数据、实例（动力源泉）
- 性能-Performance：方法针对任务的性能评估准则（检验指标）

###  3.2. <a name='3-2'>例子</a>
- T：人脸识别
    - A：线性回归
    - E：已标定身份的人脸图片数据
    - P：人脸识别准确率
- T：象棋博弈
    - A: 人工神经网络
    - E: 指令化棋谱
    - P: 对随机对手的获胜比率
- T：股价预测
    - A: 多项式回归
    - E: 不同股票近三年各交易日股价数据
    - P: 估价误差（方差）

##  4. <a name='4'>基本任务</a>
机器学习有四个基本任务，所有的机器学习的应用与子领域都是这几个基本任务组成的：
- 回归（Regression）
- 分类（Classification）
- 聚类（Clustering）
- 表征（Representation）

### 4.1 <a name='4-1'>回归（Regression）</a>
回归，是一种分析手段，用于**解决预测问题**。除开逻辑回归外，它一般是用于预测连续型数据，**等价于函数拟合**。可以用于形状分析、表情分析、运动分析等
> 就像炒菜一样，我们每次都会尝一口，然后根据与理想味道的偏差来加料或者补水，最终得到最理想的结果；下次炒菜的时候，我们就有了这么个模型，可以预测到大概需要的调料数量，得到理想的结果。也是数据（经验）到模型的过程。

它最早源自于**高尔顿和学生皮尔逊**发现的一个神奇的生物遗传现象：如果父母双亲都比较高一些，那么生出的子女身高会低于父母的平均身高；反之，如果父母双亲都比较矮一些，那么生出的子女身高要高于父母平均身高。同样体重也如此，它们总是会向一个标准数值回归。

<div align=center>
<img src="/img/pics/1-3.png" />
</div>

### 4.2 <a name='4-2'>分类（Classification）与 聚类（Clustering）</a>
分类和聚类一起讲，是因为它们其实非常像，唯一的区别就是一个是有监督学习，一个是无监督学习。（监督指的是学习时样本有无标签）

**分类**是根据一些给定的已知类别标号的样本，训练某种学习机器（即得到某种目标函数），使它能够对未知类别的样本进行分类。

一般用于：
- 分类（图像、视频、文本……..） 
- 识别（语音、人脸、指纹…….） 
- 检测（行人、车辆、军事目标…….）

<div align=center>
<img src="/img/pics/1-4.png" />
</div>

**聚类**是给定一些无标签样本，将其分成由类似对象组成的多个类。

一般用于：
- 分割（图像、视频）、背景建模
- 数据挖掘、数据恢复
- 字典学习（视觉信息，文本）
<div align=center>
<img src="/img/pics/1-5.png" />
</div>

### 4.3 <a name='4-3'>表征（Representation）</a>
表征用于特征提取，是一种将原始数据转换成为更容易被机器学习应用的数据的过程，也就是为前面三个任务解决数据的问题，它一般用于数据重构和信息检索。


##  5. <a name='5'>方法分类</a>
我们可以根据学习形式进行方法分类，就像之前提到分类和聚类的区别一样，
我们将学习方法分为：
- **有监督学习（Supervised Learning）** 
    - 数据都有明确的标签，根据机器学习产生的模型可以将新数据分到一个明确的类或得到一个预测值。
    - 典型：支持向量机、贝叶斯分类器、决策树、线性判别分析…….
- **无监督学习（Unsupervised Learning）** 
    - 数据没有标签，机器学习出的模型是从数据中提取出来的模式（提取决定性特征或者聚类等）
    - 典型：K均值、Meanshift、主成分分析、典型相关分析……
- **半监督学习（Semi-supervised Learning）** 
    - 部分数据有明确的标签，根据机器学习产生的模型可以将新数据分到一个明确的类或得到一个预测值。
    - 典型：图直推学习、超图直推学习……

##  6. <a name='6'>基本术语</a>
我们以西瓜书上的例子来讲：

> 假设我们收集了一批西瓜的数据，例如：（色泽=青绿;根蒂=蜷缩;敲声=浊响)， (色泽=乌黑;根蒂=稍蜷;敲声=沉闷)， (色泽=浅自;根蒂=硬挺;敲声=清脆)……每对括号内是一个西瓜的记录。

那么：
- **数据集（dataset）**：所有数据的集合。（所有的西瓜数据）
- **示例（instance）或样本（sample）**：每一条数据。（某一个西瓜的数据）
- **样例（example）**：有标签的示例。（西瓜数据包括西瓜类型）
- **特征（feature）或属性（attribute）**：单个特点。属性即事物本身所固有的性质。特征即一事物异于其他事物的特点。（色泽或根缔或敲声）
- **属性空间, 样本空间, 输入空间, 假设空间，版本空间**：都是属性张成的空间，但是里面包含不同的点。
- **假设空间**：包含所有可能的假设点的空间（比如所有属性组合的西瓜数据点）。
- **版本空间（version space）**： 与训练集一致的假设集合，是通过训练集筛选过的假设空间，它随训练集而变化。
- **特征向量**：一条记录在对应空间中对应的坐标向量。（我们可以称每个西瓜记录都是一个特征向量，如（色泽=青绿;根蒂=蜷缩;敲声=浊响)）
- **特征空间**：排除线性相关和对模型构建没有益处后的属性，形成的新属性空间。
- **维数（dimensionality）**：一个样本的特征数。（该西瓜的例子维数为3）（当维数非常大时，也就是现在说的“维数灾难”）
- **训练集（training set）**：所有训练样本的集合，特殊集合。
- **测试集（testing set）**：所有测试样本的集合，一般集合。
- **泛化（generalization）**：在训练集上训练好的模型在测试集上的效果，即从特殊到一般的效果。
- **独立同分布(i.i.d.)**
    - 每次抽样之间是没有关系的，不会相互影响
    - 每次抽样，样本都服从同样的一个分布
# <a name='kw'>勘误表</a>
用于订正书中的错误内容

https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/MLbook2016.htm
# <a name='data'>数据集</a>
http://archive.ics.uci.edu/ml/index.php
